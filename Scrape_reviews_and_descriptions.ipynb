{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"yelp-logo.png\"  width=130>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "# Scraping User Reviews from Yelp!\n",
    "\n",
    "In the notebook below, we walk through the scraping process to grab the companies reviews and the comanpy descriptions.\n",
    "\n",
    "The steps are as follows:\n",
    "- import librarys\n",
    "- create empty dictionary \n",
    "- use the fuction we defined in Mod_5_functions and scrape reviews\n",
    "- Pickle the file\n",
    "- Use the set of compnaies and scrape their descriptions\n",
    "\n",
    "\n",
    "#### Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from Mod_5_functions import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_dict = {'comapny_source':[],'company_loc':[],'rev_comp_rating':[],\n",
    "               'rev_comp_reviews':[],'rev_comp_url':[],'rev_company_name':[],\n",
    "               'userUrl':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the function get_all_reviews below.\n",
    "\n",
    "You need to specify a company url for their Yelp page to start. Because I am obsessed with Peloton, that is where I started. A few things to note, the **parameters** for this function are: **url_1, r_dict, review_num, company_count, starter_index**. \n",
    "\n",
    "*r_dict* is the dictionary we definied above, *review_num* is the number of reviewers you want to get from each company, *company_count* is the number of how many comapny sites we want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.yelp.com/biz/peloton-new-york?osq=peloton'\n",
    "\n",
    "reviews_df = get_all_reviews(url,review_dict,review_num, company_count,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function itself will save the dictionary after it hits 100 company pages scraped. However, if you do more or less than that, then lets save it now. **Parameters: Obj (aka our dictionary) and filename.**\n",
    "\n",
    "\n",
    "Let's use the function defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file(review_dict, 'data_folder_name/filename.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a set list of the compnaies we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp_urls = list(set(review_dict['rev_comp_url']))\n",
    "comp_names = list(set(review_dict['rev_comp_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets now get company decriptions to help with the second part of the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classPass_description():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "driver = webdriver.Chrome('/Users/elenasm7/.wdm/chromedriver/2.46/mac64/chromedriver') \n",
    "driver.get('https://classpass.com/search')\n",
    "time.sleep(1)\n",
    "search_box = driver.find_element_by_xpath('//input[@placeholder=\"Find a studio or activity\"]')\n",
    "time.sleep(1)\n",
    "search_box.send_keys(\"Barry's Bootcamp â€¢ Chelsea\")\n",
    "time.sleep(1)\n",
    "search_box.send_keys(Keys.ARROW_DOWN)\n",
    "time.sleep(1)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "time.sleep(1)\n",
    "url = driver.current_url\n",
    "driver.get('url')\n",
    "# page = requests.get(url)\n",
    "# soup = BeautifulSoup(page.content, 'lxml')\n",
    "# about = soup.find('div',{'class':'venue__about'})\n",
    "# description = about.find('p')\n",
    "time.sleep(2)\n",
    "driver.back() \n",
    "time.sleep(1)\n",
    "driver.close()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
