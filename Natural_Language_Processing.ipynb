{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:left;margin-left: -12px; margin-top: -10px\" src=\"yelp-logo-27.png\"  width=50>\n",
    "\n",
    "# Natural Language Processing\n",
    "\n",
    "In this notebook we will now go through the text data in the reviews and class/business descriptions. By preprocessing this data and using the NLP tools provided to us through *__Spacy__* and __*NLTK*__ we will be able to derive some meaning from the text to *hopefully* improve our models.\n",
    "\n",
    "The steps involved in this are as follows: \n",
    "\n",
    "1. word count\n",
    "2. character count\n",
    "3. Number of numerics\n",
    "4. Number of upper case\n",
    "5. Number of Exclamation Points (!)\n",
    "7. Count of stop words\n",
    "8. drop stop words\n",
    "9. lemmetize our words\n",
    "10. TF-IDF\n",
    "11. Sentiment Analysis\n",
    "\n",
    "#### Import needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle\n",
    "from Mod_5_functions import pickle_file,open_pickle,clean_text_column\n",
    "from nltk.corpus import stopwords\n",
    "from Mod_5_functions import return_lemma\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the pickled DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_df = open_pickle('Data/filtered_user_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. word count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_df['word_count'] = user_reviews_df.rev_comp_reviews.apply(lambda x: len(str(x).split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. character count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_reviews_df['char_count'] = user_reviews_df.rev_comp_reviews.str.len() #this includes the spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Number of numerics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_reviews_df['numerics'] = user_reviews_df.rev_comp_reviews.apply(lambda x: len([x for x in x.split() if x.isdigit()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Number of upper case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_reviews_df['upper'] = user_reviews_df.rev_comp_reviews.apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Number of Exclamation Points (!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_reviews_df['bangs'] = user_reviews_df.rev_comp_reviews.apply(lambda x: len([x for x in x.split('!')]) - 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Count of stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "user_reviews_df['stp_wrd_cnt'] = user_reviews_df.rev_comp_reviews.apply(lambda x: \n",
    "                                                                        len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comapny_source</th>\n",
       "      <th>company_loc</th>\n",
       "      <th>rev_comp_rating</th>\n",
       "      <th>rev_comp_reviews</th>\n",
       "      <th>rev_comp_url</th>\n",
       "      <th>rev_company_name</th>\n",
       "      <th>userUrl</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>bangs</th>\n",
       "      <th>stp_wrd_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peloton</td>\n",
       "      <td>370 Canal St New York, NY 10013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Planet Fitness is an affordable, no frills gym...</td>\n",
       "      <td>https://www.yelp.com/biz/planet-fitness-manhat...</td>\n",
       "      <td>Planet Fitness - Manhattan - Canal St - NY</td>\n",
       "      <td>https://www.yelp.com/user_details?userid=exPhu...</td>\n",
       "      <td>219</td>\n",
       "      <td>1189</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peloton</td>\n",
       "      <td>90 E 10th St New York, NY 10003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I purchased a Groupon for a friend and I. When...</td>\n",
       "      <td>https://www.yelp.com/biz/montauk-salt-cave-new...</td>\n",
       "      <td>Montauk Salt Cave</td>\n",
       "      <td>https://www.yelp.com/user_details?userid=exPhu...</td>\n",
       "      <td>791</td>\n",
       "      <td>4417</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peloton</td>\n",
       "      <td>1841 Broadway New York, NY 11023</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I enjoyed my class, but this was one of my lea...</td>\n",
       "      <td>https://www.yelp.com/biz/pure-barre-new-york-c...</td>\n",
       "      <td>Pure Barre - New York Columbus Circle - 60th &amp;...</td>\n",
       "      <td>https://www.yelp.com/user_details?userid=exPhu...</td>\n",
       "      <td>88</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peloton</td>\n",
       "      <td>19 W 45th St New York, NY 10036</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I came in for their Pilates Mat Fundamental cl...</td>\n",
       "      <td>https://www.yelp.com/biz/return-to-life-center...</td>\n",
       "      <td>Return To Life Center - Pilates and Functional...</td>\n",
       "      <td>https://www.yelp.com/user_details?userid=exPhu...</td>\n",
       "      <td>106</td>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peloton</td>\n",
       "      <td>140 W 23rd St New York, NY 10011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I came in for my first Peloton class awhile ba...</td>\n",
       "      <td>https://www.yelp.com/biz/peloton-new-york</td>\n",
       "      <td>Peloton</td>\n",
       "      <td>https://www.yelp.com/user_details?userid=exPhu...</td>\n",
       "      <td>206</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comapny_source                       company_loc  rev_comp_rating  \\\n",
       "0        Peloton   370 Canal St New York, NY 10013              3.0   \n",
       "1        Peloton   90 E 10th St New York, NY 10003              2.0   \n",
       "2        Peloton  1841 Broadway New York, NY 11023              3.0   \n",
       "3        Peloton   19 W 45th St New York, NY 10036              4.0   \n",
       "4        Peloton  140 W 23rd St New York, NY 10011              4.0   \n",
       "\n",
       "                                    rev_comp_reviews  \\\n",
       "0  Planet Fitness is an affordable, no frills gym...   \n",
       "1  I purchased a Groupon for a friend and I. When...   \n",
       "2  I enjoyed my class, but this was one of my lea...   \n",
       "3  I came in for their Pilates Mat Fundamental cl...   \n",
       "4  I came in for my first Peloton class awhile ba...   \n",
       "\n",
       "                                        rev_comp_url  \\\n",
       "0  https://www.yelp.com/biz/planet-fitness-manhat...   \n",
       "1  https://www.yelp.com/biz/montauk-salt-cave-new...   \n",
       "2  https://www.yelp.com/biz/pure-barre-new-york-c...   \n",
       "3  https://www.yelp.com/biz/return-to-life-center...   \n",
       "4          https://www.yelp.com/biz/peloton-new-york   \n",
       "\n",
       "                                    rev_company_name  \\\n",
       "0         Planet Fitness - Manhattan - Canal St - NY   \n",
       "1                                  Montauk Salt Cave   \n",
       "2  Pure Barre - New York Columbus Circle - 60th &...   \n",
       "3  Return To Life Center - Pilates and Functional...   \n",
       "4                                            Peloton   \n",
       "\n",
       "                                             userUrl  word_count  char_count  \\\n",
       "0  https://www.yelp.com/user_details?userid=exPhu...         219        1189   \n",
       "1  https://www.yelp.com/user_details?userid=exPhu...         791        4417   \n",
       "2  https://www.yelp.com/user_details?userid=exPhu...          88         480   \n",
       "3  https://www.yelp.com/user_details?userid=exPhu...         106         584   \n",
       "4  https://www.yelp.com/user_details?userid=exPhu...         206        1137   \n",
       "\n",
       "   numerics  upper  bangs  stp_wrd_cnt  \n",
       "0         0      5      0          100  \n",
       "1         2     19      4          331  \n",
       "2         0      2      0           39  \n",
       "3         0      2      2           39  \n",
       "4         0      9      1           91  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Next, we need to move into data cleaning. This section will be very important for the remaineder of this project and the models we run. In the next few cells we will:\n",
    "1. create a function to remove all punction\n",
    "2. lower case all of the words in our messages\n",
    "4. remove all words shorter than 3 characters\n",
    "3. remove stop words\n",
    "4. check for spelling and correct where needed\n",
    "5. remove frequent\n",
    "6. remove rare/uncommon words\n",
    "\n",
    "\n",
    "#### 1) and 2) get rid of special charaters and lower case:\n",
    "\n",
    "Use the function *clean_text_column*, which we imported above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_reviews_df.rev_comp_reviews = user_reviews_df.rev_comp_reviews.apply(lambda row: clean_text_column(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Remove Words with length of 3 characters or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_df.rev_comp_reviews = user_reviews_df.rev_comp_reviews.apply(lambda x: \n",
    "                                                                          \" \".join([i for i in li if len(i) > 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'came their pilates fundamental class loved youre completely pilates intimidated this excellent intro class some people might feel little burn youre used getting your heart rate regularly would another workout that same facility small bright airy classes intimate there boutique feel place changing rooms separated white cloth curtains your stuff goes into white open ended cubbies bathrooms very tiny nice oasis calm weird area come back'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reviews_df.rev_comp_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. drop stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english') #loads the stop words for the english language\n",
    "user_reviews_df.rev_comp_reviews = user_reviews_df.rev_comp_reviews.apply(lambda x: \" \".join(x for x in x.split() if x not in stop)) \n",
    "#returns only words that are not in the list of stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. lemmetize our words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_lemma(review,nlp):\n",
    "    doc = nlp(review)\n",
    "    return ' '.join([word.lemma_ for word in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "user_reviews_df.rev_comp_reviews = user_reviews_df.rev_comp_reviews.apply(lambda x: return_lemma(x,nlp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(user_reviews_df.rev_comp_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15722, 50)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 911876)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [word for rev in user_reviews_df.rev_comp_reviews for word in rev.split(' ')]\n",
    "len(set(test)), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out of the 911876 words in our corpus (all the words in all of the reviews), only 50 of the words are unique. That is pretty crazy, but also teling of the reviews being left. We can use this to our advantage. With t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15722x50 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 786100 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_df.rev_comp_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
